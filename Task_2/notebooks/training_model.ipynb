{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets evaluate sacrebleu tensorboard accelerate pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    MarianTokenizer,\n",
    "    MarianMTModel,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerCallback\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "import evaluate\n",
    "\n",
    "# Configuración general\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_DIR = \"../models/Translation/\"\n",
    "FINAL_MODEL_DIR = \"../models/modelo_traduccion_finetuned/\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(FINAL_MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    try:\n",
    "        # Cargar datasets (ajustar rutas según necesidad)\n",
    "        train_df = pd.read_csv('../data/processed/train/train_cleaned_source.csv', sep=';')\n",
    "        entities_df = pd.read_csv('../data/processed/train/entities_cleaned.csv', \n",
    "                                sep=';', header=None, names=['id', 'es', 'en'])\n",
    "        \n",
    "        # Aumentación de datos\n",
    "        additional_data = []\n",
    "        for _, row in entities_df.iterrows():\n",
    "            # Asegurarse de que 'en' y 'es' son cadenas\n",
    "            en_text = str(row['en']) if isinstance(row['en'], (str, bytes)) else \"\"\n",
    "            es_text = str(row['es']) if isinstance(row['es'], (str, bytes)) else \"\"\n",
    "            additional_data.extend([\n",
    "                {\"source\": en_text, \"target\": es_text},\n",
    "                {\"source\": en_text.lower(), \"target\": es_text.lower()},\n",
    "                {\"source\": en_text.upper(), \"target\": es_text.upper()}\n",
    "            ])\n",
    "            \n",
    "        # Combinar y balancear\n",
    "        enriched_df = pd.concat([\n",
    "            train_df[['source', 'target']],\n",
    "            pd.DataFrame(additional_data)\n",
    "        ], ignore_index=True).drop_duplicates().sample(frac=1, random_state=42)\n",
    "        \n",
    "        # Validación\n",
    "        assert not enriched_df.isnull().values.any(), \"Datos con valores nulos\"\n",
    "        \n",
    "        # División estratificada\n",
    "        train_data, val_data = train_test_split(\n",
    "            enriched_df,\n",
    "            test_size=0.15,\n",
    "            random_state=42,\n",
    "            stratify=pd.qcut(enriched_df['source'].apply(len), q=5)\n",
    "        )\n",
    "        \n",
    "        return Dataset.from_pandas(train_data), Dataset.from_pandas(val_data)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en carga de datos: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Datos de entrenamiento: 369542 ejemplos\n",
      "📊 Datos de validación: 65214 ejemplos\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = load_and_preprocess_data()\n",
    "print(f\"📊 Datos de entrenamiento: {len(train_dataset)} ejemplos\")\n",
    "print(f\"📊 Datos de validación: {len(val_dataset)} ejemplos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model():\n",
    "    model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name).to(device)\n",
    "    \n",
    "    # Configuración especial para entrenamiento\n",
    "    model.config.decoder_start_token_id = tokenizer.convert_tokens_to_ids([\"</s>\"])[0]  # <s> es el token de inicio\n",
    "    model.config.forced_bos_token_id = tokenizer.convert_tokens_to_ids([\"</s>\"])[0]  # <s> es el token de inicio\n",
    "    model.config.max_length = 256  # Aumentar longitud máxima\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo y tokenizador cargados correctamente\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = setup_model()\n",
    "print(\"✅ Modelo y tokenizador cargados correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch[\"source\"],\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        targets = tokenizer(\n",
    "            batch[\"target\"],\n",
    "            truncation=True,\n",
    "            max_length=256,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n",
    "        \"labels\": targets[\"input_ids\"].squeeze()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 369542/369542 [01:29<00:00, 4116.00 examples/s]\n",
      "Map: 100%|██████████| 65214/65214 [00:12<00:00, 5078.60 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    batch_size=1024,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "tokenized_val = val_dataset.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    batch_size=1024,\n",
    "    remove_columns=val_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            print(f\"🚀 Paso {state.global_step} - Pérdida: {logs.get('loss', 0):.4f}\")\n",
    "\n",
    "def create_compute_metrics(tokenizer):\n",
    "    def compute_metrics(eval_pred):\n",
    "        bleu = evaluate.load(\"bleu\")\n",
    "        sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "        \n",
    "        preds, labels = eval_pred\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        return {\n",
    "            \"bleu\": bleu.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])[\"bleu\"],\n",
    "            \"sacrebleu\": sacrebleu.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])[\"score\"]\n",
    "        }\n",
    "    return compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar checkpoints previos\n",
    "checkpoint = get_last_checkpoint(MODEL_DIR) if os.path.exists(MODEL_DIR) else None\n",
    "\n",
    "# Configurar arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=500,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=500,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"sacrebleu\",\n",
    "    greater_is_better=True,\n",
    "    predict_with_generate=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    resume_from_checkpoint=checkpoint\n",
    ")\n",
    "\n",
    "# Inicializar Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
    "    compute_metrics=create_compute_metrics(tokenizer),\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3), ProgressCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏋️ Iniciando entrenamiento...\n",
      "🔍 Checkpoint inicial: Ninguno\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='92386' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  456/92386 02:24 < 8:06:12, 3.15 it/s, Epoch 0.01/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🏋️ Iniciando entrenamiento...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 Checkpoint inicial: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNinguno\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m💾 Guardando modelo final...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(FINAL_MODEL_DIR)\n",
      "File \u001b[0;32m~/ia/lib/python3.12/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ia/lib/python3.12/site-packages/transformers/trainer.py:2536\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2537\u001b[0m ):\n\u001b[1;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"🏋️ Iniciando entrenamiento...\")\n",
    "    print(f\"🔍 Checkpoint inicial: {checkpoint or 'Ninguno'}\")\n",
    "    \n",
    "    trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    \n",
    "    print(\"💾 Guardando modelo final...\")\n",
    "    trainer.save_model(FINAL_MODEL_DIR)\n",
    "    tokenizer.save_pretrained(FINAL_MODEL_DIR)\n",
    "    \n",
    "    print(\"🧪 Evaluación final:\")\n",
    "    results = trainer.evaluate()\n",
    "    print(f\"✅ BLEU: {results['eval_bleu']:.2f}\")\n",
    "    print(f\"✅ SacreBLEU: {results['eval_sacrebleu']:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error durante el entrenamiento: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
